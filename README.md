# Git: common_crawl
Study the common-crawl dataset
 - [Common Crawl](https://commoncrawl.org/)


# Download Common Crawl datasets
- AWS
  - bucket s3://commoncrawl/, 
  - located in the US-East-1 (Northern Virginia) AWS Region.
- Https: [Example CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz](https://data.commoncrawl.org/commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz) 

# Extract the Warc file
- common_crawl.py

# Example Common-crawl Data
- common_crawl_example1.html: example html content 
- common_crawl_exmaple1_beautifulsope_lxml.html: above example1 cleaned via BeatifulSoup lxml parser. 

